{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19db67db",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "I have outlined each persons part and given them code cells.\n",
    "\n",
    "Try not to change other peoples code cells.\n",
    "\n",
    "If you can, try not to add new code cells or markdown cells as git can get confused when merging. If you absolutely need to add a new cell, make sure everyone else has saved and commited their work, commit your change with the added cells, and then make sure everyone has updated to that new change before working on the doc again.\n",
    "\n",
    "For your part try define what inputs you need and what outputs you are giving to the next person. \n",
    "\n",
    "Eg, \n",
    "\n",
    "    Preprocessing (Molly) should specify the processed dataset they want everyone to use with their models & the different pipelines they want performance metrics to be ran on\n",
    "\n",
    "    People defining models (Ross & Elsie) should clearly state what models they want to performance and efficency tests to be performed on\n",
    "\n",
    "    And people doing performance metrics (Jude & Krishan) should save and plot the metrics clearly for the conclusion\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cfc1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, learning_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge, SGDRegressor, RidgeCV\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    ")\n",
    "from pathlib import Path\n",
    "\n",
    "# For reproducibility\n",
    "RNG = 42\n",
    "np.random.seed(RNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee147c",
   "metadata": {},
   "source": [
    "Code cells for defining functions or importing special libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d925e92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Molly's code cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebbe002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ross's code cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6305d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elsie's code cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f27baa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jude's code cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d708cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krishan's code cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb303cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rawan's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8a50e",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "\n",
    "Ive just added my pre-processing from part 1, we can build on this or your own pre processing, whicherver you prefer :)\n",
    "\n",
    "### Molly:\n",
    "    \n",
    "    Removing outliers/ missing data \n",
    "\n",
    "    train-test split \n",
    "\n",
    "    Data analysis \n",
    "\n",
    "    Co-variance \n",
    "\n",
    "    Correlation \n",
    "\n",
    "    histograms/ box plots to find data distribution \n",
    "\n",
    "    Investigate column encoding vs number encoding efficiency \n",
    "\n",
    "    For every different type pre-processing you want to performance and efficiency test define a pipeline with ridge regression so that Krishan & Jude can do performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83ec1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Jude Robinson\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\abalone.data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m CSV_PATH \u001b[38;5;241m=\u001b[39m CWD \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabalone.data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load dataset as pandas DataFrame\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(CSV_PATH, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRings\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRings\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Assert Rings column exists\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Converting gender to 3 separate one-hot encoded columns\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jude Robinson\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Jude Robinson\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Jude Robinson\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\Jude Robinson\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Jude Robinson\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Jude Robinson\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\abalone.data.csv'"
     ]
    }
   ],
   "source": [
    "# Molly's code cell\n",
    "\n",
    "# dataset path\n",
    "CWD = Path.cwd()\n",
    "CSV_PATH = \"abalone.data.csv\"\n",
    "\n",
    "# Load dataset as pandas DataFrame\n",
    "df = pd.read_csv(CSV_PATH, sep=\",\")\n",
    "assert \"Rings\" in df.columns, \"Expected 'Rings' column.\" # Assert Rings column exists\n",
    "\n",
    "# Converting gender to 3 separate one-hot encoded columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), ['gender'])  # Apply OneHotEncoder to column 3\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the other columns\n",
    ")\n",
    "\n",
    "datEnc = preprocessor.fit_transform(df)\n",
    "\n",
    "# Get the new column names created by the transformer\n",
    "new_columns = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Create a new DataFrame with the transformed data and new column names\n",
    "dfEnc = pd.DataFrame(datEnc, columns=new_columns)\n",
    "dfEnc = dfEnc.rename(columns={\"cat__gender_F\": \"gender_F\", \"cat__gender_I\": \"gender_I\", \"cat__gender_M\": \"gender_M\", \"remainder__Length\": \"length\", \"remainder__Diameter\": \"diameter\", \"remainder__Height\" : \"height\", \"remainder__Whole weight\" : \"whole_weight\", \"remainder__Shucked weight\": \"shucked_weight\", \"remainder__Viscera weight\" : \"viscera_weight\", \"remainder__Shell weight\" : \"shell_weight\", \"remainder__Rings\" : \"Rings\"})\n",
    "\n",
    "# Summary statistics and check for missing values\n",
    "display(dfEnc.describe(include='all'))\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(dfEnc.isna().sum().sort_values(ascending=False))\n",
    "\n",
    "# Check for duplicates\n",
    "num_duplicates = dfEnc.duplicated().sum()\n",
    "print(f\"Number of duplicates: {num_duplicates}\")\n",
    "\n",
    "# Plot histograms for each feature\n",
    "df.hist(bins=15, figsize=(10, 10))\n",
    "plt.suptitle(\"Feature Distributions\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Remove entries with outliers in 'height' feature\n",
    "height_threshold = dfEnc['height'].quantile(0.99)  # 99th percentile\n",
    "dfEnc = dfEnc[dfEnc['height'] <= height_threshold]\n",
    "dfEnc = dfEnc[dfEnc['height'] > 0]\n",
    "\n",
    "# re-plot height distribution after removing outliers\n",
    "print(\"After pre-processing:\")\n",
    "display(dfEnc.describe(include='all'))\n",
    "dfEnc.hist(bins=15, figsize=(10, 10))\n",
    "plt.suptitle(\"Feature Distributions After pre-processing\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = dfEnc.drop(columns=[\"Rings\"])\n",
    "y_reg = dfEnc[\"Rings\"]\n",
    "\n",
    "# Split data into training and testing sets for regression\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=RNG\n",
    ")\n",
    "\n",
    "# Fold datasets for cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72603041",
   "metadata": {},
   "source": [
    "### Jude:\n",
    "\n",
    "    Do performance analysis of different pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jude's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d7cb6",
   "metadata": {},
   "source": [
    "### Krishan:\n",
    "\n",
    "    Do efficiency analysis of different pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krishan's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ead3f8",
   "metadata": {},
   "source": [
    "# Comparing Different Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa5dd6c",
   "metadata": {},
   "source": [
    "Im just putting ideas for models we could use, feel free to change :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd2d4f",
   "metadata": {},
   "source": [
    "## Ridge regression\n",
    "\n",
    "### Ross:\n",
    "\n",
    "    Implement model pipeline with tuned hyperparameters\n",
    "\n",
    "    Train model\n",
    "\n",
    "    Use Model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d59facb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m pipe_ridge_cv \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m     11\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m\"\u001b[39m, RobustScaler()),\n\u001b[0;32m     12\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mridge_cv\u001b[39m\u001b[38;5;124m\"\u001b[39m, RidgeCV(alphas \u001b[38;5;241m=\u001b[39m alphas_to_test, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     13\u001b[0m ])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Fit RidgeCV pipeline\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m pipe_ridge_cv\u001b[38;5;241m.\u001b[39mfit(X_train_r, y_train_r)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Get best alpha\u001b[39;00m\n\u001b[0;32m     17\u001b[0m best_alpha_ridge \u001b[38;5;241m=\u001b[39m pipe_ridge_cv\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mridge_cv\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39malpha_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_r' is not defined"
     ]
    }
   ],
   "source": [
    "# Ross's code \n",
    "\n",
    "\n",
    "### Ridge regression ###\n",
    "\n",
    "# Define the range of alphas to test for regularization\n",
    "alphas_to_test = np.logspace(-4, 2, 100) # Test 100 values from 0.0001 to 100\n",
    "\n",
    "#RidgeCV Pipeline\n",
    "pipe_ridge_cv = Pipeline([\n",
    "    (\"scaler\", RobustScaler()),\n",
    "    (\"ridge_cv\", RidgeCV(alphas = alphas_to_test, cv=5, scoring='neg_mean_squared_error'))\n",
    "])\n",
    "# Fit RidgeCV pipeline\n",
    "pipe_ridge_cv.fit(X_train_r, y_train_r)\n",
    "# Get best alpha\n",
    "best_alpha_ridge = pipe_ridge_cv.named_steps['ridge_cv'].alpha_\n",
    "print(f\"Best alpha found by RidgeCV: {best_alpha_ridge}\")\n",
    "\n",
    "# Cross Validate Pipeline\n",
    "cv_reg = cross_validate(\n",
    "    pipe_ridge_cv, X_train_r, y_train_r, cv=kf, n_jobs=-1,\n",
    "    scoring=(\"r2\", \"neg_mean_squared_error\", \"neg_mean_absolute_error\"),\n",
    "    return_train_score=True\n",
    ")  \n",
    "\n",
    "# Fit model on training data\n",
    "t0 = time.time()\n",
    "\n",
    "train_time = time.time() - t0\n",
    "\n",
    "# Predict on test data\n",
    "t1 = time.time()\n",
    "y_pred_r = pipe_ridge_cv.predict(X_test_r)\n",
    "pred_time = time.time() - t1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14bd723",
   "metadata": {},
   "source": [
    "### Jude:\n",
    "\n",
    "    Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad192ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jude's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc059610",
   "metadata": {},
   "source": [
    "### Krishan:\n",
    "\n",
    "    Efficiency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krishan's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c37957",
   "metadata": {},
   "source": [
    "## Nieve Bayes\n",
    "\n",
    "### Ross:\n",
    "\n",
    "    Implement model pipeline with tuned hyperparameters\n",
    "\n",
    "    Train model\n",
    "\n",
    "    Use Model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55890979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ross's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642a01c",
   "metadata": {},
   "source": [
    "### Jude:\n",
    "\n",
    "    Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jude's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1f455",
   "metadata": {},
   "source": [
    "### Krishan:\n",
    "\n",
    "    Efficiency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1856f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krishan's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071bc4d5",
   "metadata": {},
   "source": [
    "## SVR\n",
    "\n",
    "### Ross:\n",
    "\n",
    "    Implement model pipeline with tuned hyperparameters\n",
    "\n",
    "    Train model\n",
    "\n",
    "    Use Model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d00e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ross's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f7c9c",
   "metadata": {},
   "source": [
    "### Jude:\n",
    "\n",
    "    Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jude's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f81b4",
   "metadata": {},
   "source": [
    "### Krishan:\n",
    "\n",
    "    Efficiency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45161d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krishan's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16fe4e2",
   "metadata": {},
   "source": [
    "## Forest of Tree\n",
    "\n",
    "### Elsie:\n",
    "\n",
    "    Implement model pipeline with tuned hyperparameters\n",
    "\n",
    "    Train model\n",
    "\n",
    "    Use Model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056706a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elsie's code cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f1a83",
   "metadata": {},
   "source": [
    "### Jude:\n",
    "\n",
    "    Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jude's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf1dd3",
   "metadata": {},
   "source": [
    "### Krishan:\n",
    "\n",
    "    Efficiency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krishan's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3104795b",
   "metadata": {},
   "source": [
    "## Voting Regressor\n",
    "\n",
    "### Elsie:\n",
    "\n",
    "    Implement model pipeline with tuned hyperparameters\n",
    "\n",
    "    Train model\n",
    "\n",
    "    Use Model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elsie's code cell\n",
    "print(\"End of notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab9aba",
   "metadata": {},
   "source": [
    "### Jude:\n",
    "\n",
    "    Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5628ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jude's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d015e",
   "metadata": {},
   "source": [
    "### Krishan:\n",
    "\n",
    "    Efficiency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krishan's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72801c9a",
   "metadata": {},
   "source": [
    "## Stacking Regressor\n",
    "\n",
    "### Elsie:\n",
    "\n",
    "    Implement model pipeline with tuned hyperparameters\n",
    "\n",
    "    Train model\n",
    "\n",
    "    Use Model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257e1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elsie's code cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb9dd1f",
   "metadata": {},
   "source": [
    "### Jude:\n",
    "\n",
    "    Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbced50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jude's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1815e52d",
   "metadata": {},
   "source": [
    "### Krishan:\n",
    "\n",
    "    Efficiency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krishan's code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49928b",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "### Rawan:\n",
    "\n",
    "    Create any graphs to compare model metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3459d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rawan's code cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
