{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19db67db",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "I have outlined each persons part and given them code cells.\n",
    "\n",
    "Try not to change other peoples code cells.\n",
    "\n",
    "For your part try define what inputs you need and what outputs you are giving to the next person. \n",
    "\n",
    "Eg, \n",
    "\n",
    "    Preprocessing (Molly) should specify the processed dataset they want everyone to use with their models & the different pipelines they want performance metrics to be ran on\n",
    "\n",
    "    People defining models (Ross & Elsie) should clearly state what models they want to performance and efficency tests to be performed on\n",
    "\n",
    "    And people doing performance metrics (Jude & Krishan) should save and plot the metrics clearly for the conclusion\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cfc1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, learning_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge, SGDRegressor, RidgeCV\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    ")\n",
    "\n",
    "# For reproducibility\n",
    "RNG = 42\n",
    "np.random.seed(RNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8a50e",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "\n",
    "Ive just added my pre-processing from part 1, we can build on this or your own pre processing, whicherver you prefer :)\n",
    "\n",
    "## Molly:\n",
    "    \n",
    "    Removing outliers/ missing data \n",
    "\n",
    "    train-test split \n",
    "\n",
    "    Data analysis \n",
    "\n",
    "    Co-variance \n",
    "\n",
    "    Correlation \n",
    "\n",
    "    histograms/ box plots to find data distribution \n",
    "\n",
    "    Investigate column encoding vs number encoding efficiency \n",
    "\n",
    "    For every different type pre-processing you want to performance and efficiency test define a pipeline with ridge regression so that Krishan & Jude can do performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset path\n",
    "DATA_PATH = r\"abalone.data.csv\" \n",
    "\n",
    "# Load dataset as pandas DataFrame\n",
    "df = pd.read_csv(DATA_PATH, sep=\",\")\n",
    "assert \"Rings\" in df.columns, \"Expected 'Rings' column.\" # Assert Rings column exists\n",
    "\n",
    "# Converting gender to 3 separate one-hot encoded columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), ['gender'])  # Apply OneHotEncoder to column 3\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the other columns\n",
    ")\n",
    "\n",
    "datEnc = preprocessor.fit_transform(df)\n",
    "\n",
    "# Get the new column names created by the transformer\n",
    "new_columns = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Create a new DataFrame with the transformed data and new column names\n",
    "dfEnc = pd.DataFrame(datEnc, columns=new_columns)\n",
    "dfEnc = dfEnc.rename(columns={\"cat__gender_F\": \"gender_F\", \"cat__gender_I\": \"gender_I\", \"cat__gender_M\": \"gender_M\", \"remainder__Length\": \"length\", \"remainder__Diameter\": \"diameter\", \"remainder__Height\" : \"height\", \"remainder__Whole weight\" : \"whole_weight\", \"remainder__Shucked weight\": \"shucked_weight\", \"remainder__Viscera weight\" : \"viscera_weight\", \"remainder__Shell weight\" : \"shell_weight\", \"remainder__Rings\" : \"Rings\"})\n",
    "\n",
    "# Summary statistics and check for missing values\n",
    "display(dfEnc.describe(include='all'))\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(dfEnc.isna().sum().sort_values(ascending=False))\n",
    "\n",
    "# Check for duplicates\n",
    "num_duplicates = dfEnc.duplicated().sum()\n",
    "print(f\"Number of duplicates: {num_duplicates}\")\n",
    "\n",
    "# Plot histograms for each feature\n",
    "df.hist(bins=15, figsize=(10, 10))\n",
    "plt.suptitle(\"Feature Distributions\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Remove entries with outliers in 'height' feature\n",
    "height_threshold = dfEnc['height'].quantile(0.99)  # 99th percentile\n",
    "dfEnc = dfEnc[dfEnc['height'] <= height_threshold]\n",
    "dfEnc = dfEnc[dfEnc['height'] > 0]\n",
    "\n",
    "# re-plot height distribution after removing outliers\n",
    "print(\"After pre-processing:\")\n",
    "display(dfEnc.describe(include='all'))\n",
    "dfEnc.hist(bins=15, figsize=(10, 10))\n",
    "plt.suptitle(\"Feature Distributions After pre-processing\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = dfEnc.drop(columns=[\"Rings\"])\n",
    "y_reg = dfEnc[\"Rings\"]\n",
    "\n",
    "# Split data into training and testing sets for regression\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=RNG\n",
    ")\n",
    "\n",
    "# Fold datasets for cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RNG)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72603041",
   "metadata": {},
   "source": [
    "## Jude:\n",
    "\n",
    "    Do performance analysis of different pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d7cb6",
   "metadata": {},
   "source": [
    "## Krishan:\n",
    "\n",
    "    Do efficiency analysis of different pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing efficiency metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ead3f8",
   "metadata": {},
   "source": [
    "# Comparing Different Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa5dd6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58dc92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
